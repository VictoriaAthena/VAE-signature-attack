{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A sample of a code of the VGG16 signature verification model trained on CEDAR dataset and the sythetic attack process"
      ],
      "metadata": {
        "id": "FEZsn3QhNc5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2                 # working with, mainly resizing, images\n",
        "import numpy as np         # dealing with arrays\n",
        "import os                  # dealing with directories\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn import metrics "
      ],
      "metadata": {
        "id": "hr5Jz8gn4NLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JMdGGEb3n1m"
      },
      "outputs": [],
      "source": [
        "path=os.getcwd()\n",
        "#link to the datasets. The images must be converted into numpy arrays with size 150x220 and saved in the files. \n",
        "#cedar dataset has 55 contributors, each has 24 genuine samples and 24 forgery samples\n",
        "train_real_path=path+\"/real_CEDAR.npy\"\n",
        "train_fake_path=path+\"/forg_CEDAR.npy\"\n",
        "syn_real_path= path+\"/synthetic_real_CEDAR.npy\"\n",
        "syn_fake_path= path+\"/synthetic_forg_CEDAR.npy\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model():\n",
        "  #the model runs on GPU\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150, 220, 3))\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "    add_model = Sequential()\n",
        "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    add_model.add(Dense(256, activation='relu'))\n",
        "    add_model.add(Dense(2, activation='sigmoid'))\n",
        "    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "9acuxyC04lVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_fake_path, 'rb') as f:\n",
        "    fake=np.load(f)\n",
        "with open(train_real_path, 'rb') as f:\n",
        "    real=np.load(f)\n",
        "with open(syn_real_path, 'rb') as f:\n",
        "      syn_real=np.load(f)\n",
        "with open(syn_fake_path, 'rb') as f:\n",
        "      syn_fake=np.load(f) "
      ],
      "metadata": {
        "id": "-A1ZSPB-MOFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generate_cedar(index,syn=False):\n",
        "  #generate train and test features for an individual \n",
        "  train_features = []\n",
        "  train_labels = []\n",
        "  test_features = []\n",
        "  test_labels = []\n",
        "  syn_real_features = []\n",
        "  syn_real_labels = []\n",
        "  syn_fake_features = []\n",
        "  syn_fake_labels = []\n",
        "\n",
        "  #the real/forg human dataset would be arranged sequentially - first sample of the first user, second sample of the first user, and vice versa\n",
        "  for j in range (0,16) :\n",
        "    train_features.append(real[index*24+j])\n",
        "    train_labels.append(1)\n",
        "    train_features.append(fake[index*24+j])\n",
        "    train_labels.append(0)\n",
        "  for j in range (16,24) :\n",
        "    test_features.append(real[index*24+j])\n",
        "    test_labels.append(1)\n",
        "    test_features.append(fake[index*24+j])\n",
        "    test_labels.append(0)\n",
        "  if syn: \n",
        "  #for each human sample we generate 9 synthetic samples, \n",
        "  #the arrangement is similar to human datasets - 9 synthetic from first sample of the first user, 9 from the second sample of the first user, and vice versa\n",
        "  for j in range (0,16) :\n",
        "    for i in range(16,24):\n",
        "      for j in range(9):\n",
        "        syn_real_features.append(syn_real[index*24*9+i*9+j])\n",
        "        syn_real_labels.append(0)\n",
        "        syn_fake_features.append(syn_fake[index*24*9+i*9+j])\n",
        "        syn_fake_labels.append(0)\n",
        "  train_features = np.asarray(train_features).astype('float32')\n",
        "  test_features = np.asarray(test_features).astype('float32')\n",
        "  syn_real_features = np.asarray(syn_real_features).astype('float32')\n",
        "  syn_fake_features = np.asarray(syn_fake_features).astype('float32')\n",
        "  train_features = train_features/ 255.\n",
        "  test_features = test_features / 255.\n",
        "  syn_real_features = syn_real_features /255.\n",
        "  syn_fake_features = syn_fake_features /255.\n",
        "  train_labels = np.array(train_labels)\n",
        "  test_labels = np.array(test_labels)\n",
        "  syn_real_labels = np.array(syn_real_labels)\n",
        "  syn_fake_labels = np.array(syn_fake_labels)\n",
        "  train_labels = to_categorical(train_labels)\n",
        "  return train_features,train_labels,test_features,test_labels,syn_real_features,syn_real_labels,syn_fake_features,syn_fake_labels"
      ],
      "metadata": {
        "id": "OfzlxNc-3qzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(data,model):\n",
        "  tp = model.predict(data)\n",
        "  #output has 2 values - probability of being 0 (fake) and probability of being 1 (real)\n",
        "  output=[]\n",
        "  for i in tp:\n",
        "    output.append(i[1])\n",
        "  return output"
      ],
      "metadata": {
        "id": "_0NBAEGXvSn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(data,labels):\n",
        "  output =[]\n",
        "  for i in data:\n",
        "    #threshold 0.5\n",
        "    if i>0.5: #real \n",
        "      output.append(1)\n",
        "    else:\n",
        "      output.append(0)\n",
        "  return sklearn.metrics.accuracy_score(output,labels)"
      ],
      "metadata": {
        "id": "5USNkaY_Ia6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def far_frr_cal(data,compare):\n",
        "  #calculation of far and frr through out the threshold\n",
        "  real = 0\n",
        "  fake = 0\n",
        "  frr = []\n",
        "  far =[]\n",
        "  for i in range (11):\n",
        "    frr.append(0)\n",
        "    far.append(0)\n",
        "  for i in range (len(data)):\n",
        "    if compare[i]==1:\n",
        "      real+=1\n",
        "    else:\n",
        "      fake+=1\n",
        "  for i in range (len(data)):\n",
        "    for j in range(11):\n",
        "      tp = 1\n",
        "      if data[i] <= j*0.1:\n",
        "        tp = 0\n",
        "      if tp!=compare[i]:\n",
        "        if compare[i]==0:\n",
        "          far[j]+=1\n",
        "        else:\n",
        "          frr[j]+=1\n",
        "  for i in range (11):\n",
        "    frr[i]/=real/100\n",
        "    far[i]/=fake/100\n",
        "  return [far,frr]\n",
        "         \n",
        "def far_cal(data,compare):\n",
        "  far =[]\n",
        "  for i in range (11):\n",
        "    far.append(0)\n",
        "  for i in range (len(data)):\n",
        "    for j in range(11):\n",
        "      tp = 1\n",
        "      if data[i] <= j*0.1:\n",
        "        tp = 0\n",
        "      if tp==1:\n",
        "        far[j]+=1\n",
        "  for i in range (11):\n",
        "    far[i]/=len(data)/100\n",
        "  return far\n",
        "         \n"
      ],
      "metadata": {
        "id": "fGSwqo76Jke8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_person(index):\n",
        "  train_features,train_labels,test_features,test_labels,syn_real_features,syn_real_labels,syn_fake_features,syn_fake_labels = data_generate_cedar(index,True)\n",
        "  batch_size = 32\n",
        "  epochs = 30\n",
        "  model = init_model()\n",
        "  history = model.fit(train_features, train_labels, batch_size=batch_size,epochs=epochs,verbose=1)  \n",
        "  human_test = make_prediction(test_features,model)\n",
        "  syn_real_test = make_prediction(syn_real_features,model)\n",
        "  syn_fake_test = make_prediction(syn_fake_features,model)\n",
        "  return acc(human_test,test_labels), acc(syn_real_test ,syn_real_labels),acc(syn_fake_test,syn_fake_labels), far_frr_cal(human_test,test_labels),far_cal(syn_real_test ,syn_real_labels),far_cal(syn_fake_test ,syn_fake_labels)"
      ],
      "metadata": {
        "id": "6bLEPxUCUG7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CVojXmmcaZk",
        "outputId": "95c088ec-d625-4fb1-8ed8-9eb7c54096d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_frr = []\n",
        "for i in range (11):\n",
        "  human_frr.append(0)\n",
        "human_far = []\n",
        "for i in range (11):\n",
        "  human_far.append(0)\n",
        "syn_real_far = []\n",
        "for i in range (11):\n",
        "  syn_real_far.append(0)\n",
        "syn_fake_far = []\n",
        "for i in range (11):\n",
        "  syn_fake_far.append(0)\n",
        "for i in range (0, no_contrib):\n",
        "  print('----------- evaluating person '+str(i+1)+'--------------')\n",
        "  #\n",
        "  a,b,c,x,y,z = evaluate_person(i)\n",
        "  #\"human_far\",\"human_frr\",\"synt_real_far\", \"synt_fake_far\"\n",
        "  print([x[0][6],x[1][6],y[6],z[6]])\n"
      ],
      "metadata": {
        "id": "9Fi-FeL3YVuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}